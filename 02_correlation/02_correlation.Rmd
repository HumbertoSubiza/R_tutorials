---
title:  "Correlação e regressão linear simples"
author: "Walter Humberto Subiza Pina"
date: "`r format(Sys.Date())`"
output:
  html_document:
    keep_md: TRUE
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo      = TRUE, 
                      warning   = FALSE, 
                      message   = FALSE, 
                      fig.path  = 'figuras/', 
                      fig.ext   = 'png',
                      fig.align = 'center')

```

---

## Tutorial de correlação

---

Disclaimer:

Parte deste material encontra-se em (<https://www.datacamp.com/>) e em "Online Statistics Education" (<http://onlinestatbook.com/>), sendo de livre acesso (open source). Foi traduzido ao português para melhor difussão, e foram feitas algumas modificações nos fragmentos de código para melhor visualização.

### Correlação

#### Alguns conceitos teóricos

**Correlação é uma medida de dependência ou associação entre duas variáveis.**

**Correlação** é apenas uma relação estatística, por isso sempre se deve ter em mente que a correlação entre duas variáveis não significa que uma seja a causa do comportamento da outra. Assim sendo, outros testes e medições devem ser feitos para confirmar essa hipótese.

Lembrando que pode ainda existir forte dependência entre duas variáveis sem ter correlação.

Existem diferentes coeficientes de correlação, um dos mais usados é o coeficiente de correlação de Pearson. 

O coeficiente de Pearson varia desde o valor **1**, quando as variáveis são perfeita e positivamente correlacionadas, ou seja variam no mesmo sentido;  a **0** quando não existe nenhum tipo de correlação até **-1** quando elas são perfeita e negativamente correlacionadas ou seja variam em sentidos opostos.

Como a correlação calcula-se entre cada dois pares de elementos de cada variável, não faz sentido se algum elemento das variaveis esta faltando ou seja é **NA**. Por isso o calculo so pode ser feito sobre variáveis completas, sem NAs. Vamos ver alguns exemplos de correlação, sendo que voltaremos a analisa-la num exercicio posterior.

---

**Correlação positiva entre 1 e 0 aprox.:**

<center>![](D:/Users/humberto.pina/Documents/R/R_tutorials/02_correlation/figuras/corr01.png)</center>


---

**Correlação negativa entre -1 e 0 aprox.:**

<center>![](D:/Users/humberto.pina/Documents/R/R_tutorials/02_correlation/figuras/corr02.png)</center>

---

#### Calculo da correlação

Com a finalidade de entender como a correlação e calculada, vamos definir duas variaveis com apenas 5 elementos cada, "X" e "Y" e coloca-las num dataframe. Veja que, como as duas variaveis crescem, a correlação independentemente do seu valor numérico, deveria ser positiva.

```{r corr01}
X <- c(3, 6, 8, 8, 9)
Y <- c(7, 9, 13, 15, 16)
plot(X, Y, pch = 19, cex = 2)
pearson <- data.frame(X,Y)
```

---

Como _primeiro passo_, vamos calcular a media de cada variavel.

```{r corr02}
mediax <- mean(X)
mediay <- mean(Y)
```


No _segundo passo_ vamos substrair de cada variável, o valor a media e adicionamos uma nova coluna ("x","y"). Este numero representa o desvio de cada valor do centro da variavel. O cálculo será repetido para a variavel "Y". Para o cálculo e a atualização do dataframe usaremos a função _mutate_ do pacote _dplyr_. O sumatorio das novas variaveis "x" e "y", deve ser sempre zero.


```{r corr03}
library(dplyr)
pearson <- mutate(pearson, x = X - mediax, y = Y - mediay)
round(sum(pearson$x),1)
round(sum(pearson$y),1)

```

---

No _terceiro passo_, multiplicamos as colunas criadas. 

```{r corr04}
pearson$xy <- pearson$x * pearson$y
```

Esta nova coluna revela coisas interessantes sobre o comportamento das variaveis e sua correlação. No caso de não existir correlação ou ser muito pequena, os valores de "x" e "y" seriam tanto positivos como negativos nas mesmas linhas e seu somatorio deveria ser um numero muito pequeno. 

Já no caso de existir correlação, o sumatório deve dar um numero maior, ja que as diferenças com a media serão simultaneamente positivas ou negativas.

```{r corr05}
sum(pearson$xy)
```

---

Finalmente, no _quinto passo_ vamos adicionar duas novas colunas, com o quadrado de cada variavel, "x" e "y", ou seja a variancia de cada uma delas.

```{r corr06}
pearson <- mutate(pearson, x2 = x * x, y2 =  y * y)
pearson
```

---

O coeficiente de correlação de Pearson está incluído também quando efetuamos o cálculo de uma regressão linear, já que integra a formula do coeficiente de inclinação da reta. Existem diversas fórmulas para o cálculo, vamos primeiro apresentar uma que conceitualmente tem mais sentido.

A equação que calcula o coeficiente de Pearson é

$$r ~ = ~ \frac{\sum(x - \bar{x})~ * ~(y - \bar{y})}{S{^2}_x ~*~ S{^2}_y}~~ (1)$$

sendo:

- _r_, o valor da correlação

- $S{^2}_x$, a variancia de _x_

- $S{^2}_y$, a variancia de _y_

- $\bar{x}$ e $\bar{y}$, os valores medios de x e y

Uma outra equação que calcula o coeficiente de Pearson, desta vez sem o uso da variancia é:

---

$$r ~ = ~ \frac{\sum(xy) - \frac{\sum(x)~*~\sum(y)} {N}} {\sqrt{(\sum{x^2}~-~\frac{(\sum{x})^2}{N}}~*~{\sqrt{(\sum{y^2}~-~\frac{(\sum{y})^2}{N}}}}~~ (2)$$

---

O calculo pelas formulas (1) e (2), assim como com a função _cor_ do R, e:

---

```{r corr07}
# Correlacao pela formula 1
(corr1 <- sum(pearson$xy) / sqrt(sum(pearson$x2) * sum(pearson$y2)))

# Correlacao pela formula 2, sem calculo da variancia
# numerador
num <- sum(pearson$xy) - ((sum(pearson$x) * sum(pearson$y)) / length(pearson$X))
#denominador
denom1 <- sqrt(sum(pearson$x2) - (sum(pearson$x)^2 / length(pearson$X)))
denom2 <- sqrt(sum(pearson$y2) - (sum(pearson$y)^2 / length(pearson$X)))
denom <- denom1*denom2

# correlacao
(corr2 <- num/denom)

# Correlacao pela função R
cor(X,Y)
```

Vamos analisar como seria o caso de não existir correlação ou ser de muito pequeno valor. Um novo dataframe "pearson2", vai conter as novas variaveis, desta vez geradas com uma correlação fraca. Os cálculos serão feitos da mesma forma que no caso anterior e verificaremos a soma do produto "xy".

```{r corr08}
# novo dataframe com duas variaveis
pearson2 <- data.frame(X, Y = c(3, 3, 6, 3, 1))
# grafico de dispersao
plot(pearson2$X, pearson2$Y, pch = 19, cex = 2)

# calculo das medias de cada variavel
mediax2 <- mean(pearson2$X)
mediay2 <- mean(pearson2$Y)

# criamos a diferenca de cada variavel com a media
pearson2 <- mutate(pearson2, x = X - mediax2, y = Y - mediay2)
# produto das diferenca das variaveis
pearson2$xy <- pearson2$x * pearson2$y
# variancia de cada variavel
pearson2 <- mutate(pearson2, x2 = x * x, y2 =  y * y)

# comprovacao do somatorio do produto, numero pequeno
# demostra que nao existe correlacao ou e fraca
sum(pearson2$xy)
```

Cálculo da correlação

```{r corr09}
# Correlacao pela formula 1
(corr2 <- sum(pearson2$xy)/ sqrt(sum(pearson2$x2) *sum(pearson2$y2)))
cor(pearson2$X, pearson2$Y)
```


---

### Introdução à Regressão

O cálculo da correlação entra no cálculo da regressão, especificamente no coeficiente da linha de regressão, e indica quando colocada num gráfico a tendência que os dados correlacionados tem.
A regressão integra a área da estatística inferencial, ou seja onde a partir de dados obtidos de uma ou mais variáveis, tentamos prever o comportamento de uma outra no futuro. _Para uma leitura mais detalhada deste tema, veja o tutorial 05 específico sobre regressão linear._

Na regressão simples, tentamos prever o comportamento de uma variavel chamada de resposta, a partir de uma outra chamada de preditora ou independente. Neste método, os valores preditos a partir da variável independente são graficados como uma linha reta. No _R_, a função base que calcula a regressão é `lm()` (_linear models_), onde indicamos  por meio de uma formula, as variáveis resposta e preditora.

Matemáticamente, uma regressão linear é encontrar a linha que melhor se ajuste aos pontos (caso simples de método de mínimos quadrados), no caso prático anterior, seria da seguinte forma:


```{r corr10}
# cálculo da regressão
reg <- lm(Y ~ X)
# gráfico dos dados e da linha de regressão
plot(Y ~ X, pch = 19, cex = 2, xlim = c(0,10), ylim = c(0,20))
abline(reg, col = "red", lwd = 2)
```

---

A função de regressão apresentada, gera um objeto lista, com diversos elementos que podem ser extraídos e visualizados de várias formas. A mais simples é a través da função `str()`, que apresenta todos os elementos da lista criada por `lm()` ou do `summary()`.

```{r corr11}
str(reg)
summary(reg)
```

Os elementos desta lista podem ser extraídos em forma individual:

```{r corr11b}
# coeficientes da linha de regressão
reg$coefficients

# resíduos da regressão
reg$residuals

# valores ajustados
reg$fitted.values
```

Ou ainda temos uma opção mais elegante e interativa com a função `listviewer::jsonedit()`.

```{r corr11c}
listviewer::jsonedit(reg, mode = "view")
```


---

#### Exercicio e gráficos de correlação

Vamos explorar diversos métodos de visualização de dados e as estatísticas que encontram-se por trás. Particularmente em relação a identificação de tendências e relações entre variáveis presentes num dataframe.

Vamos focar em conceitos como correlação e regressão, primeiro introduzindo a correlação em _R_ e os gráficos de correlação de matrizes em R, principalmente usando os pacotes _ggplot2_ and _GGally_. 
 
Finalmente vamos ver os diferentes tipos de correlação e como afetam análises posteriores.
 
#### Esclarecimentos

Neste tutorial vamos trabalhar com uma base de dados de cinema, proveniente do Kaggle, para analisar e entender melhor as relações entre variáveis.

Os dados originais encontram-se em IMDB 5000 Movie Dataset" on <https://www.kaggle.com/carolzhangdc/imdb-5000-movie-dataset/downloads/imdb-5000-movie-dataset.zip/1>.
 
#### Importando os dados

A importação será feita usando o read.csv(); os dados estão armazenados no arquivo "movies.csv".

---

```{r corr12}
movies <- read.csv("movies.csv")
```

---

#### Inspecção dos dados
  
Como primeiro passo vamos conhecer os dados. A função básica _str()_:

---

```{r  corr12b}
library(tidyverse)
str(movies, max.level = 1, vec.len = 2)
```

---

 Vemos que o dataframe contém 5043 linhas ou registros e 28 variáveis ou colunas, detalhando o nome e tipo de variável junto com uma amostra dos primeiros valores de cada uma.
 
 Entender o tipo de dados é fundamental para o análise posterior.
 
 Outra função que ajuda no conhecimento dos dados é o _summary_, veja a diferença entre as duas funções apresentadas.

---

```{r corr13}
summary(movies)
```

---

Observe cada variável e o seu resumo.
   
**Primeiras análises: calculando lucros!!**
 
Na revisão dos dados, ficou claro que algumas variáveis podiam ser manipuladas de forma de obter novas informações. 

Por exemplo, temos o ingresso bruto ("gross") e o orçamento dos filmes ("budget"), isso permite calcular o lucro por filme, usando a fórmula 

_profit = gross - budget_.  Para simplificar vamos dividir o resultado de forma de obter o valor em milhões de dólares.

---

```{r corr14}
profit <- (movies$gross - movies$budget) / 1000000

#Check the result

summary(profit)
```

---

Muito bom! podemos ver que temos alguns films coleccionadores de dinheiro e outros só de dívidas!!

 Vamos aproveitar e colocar nosso análise numa nova coluna, já que pode ajudar em análises posteriores.
 
---

```{r corr15}
# adicionando uma nova coluna com o lucro de cada filme.
movies$profit <- (movies$gross - movies$budget) / 1000000
```

---

#### Correlação

Com nossa nova coluna adicionada, podemos dar uma olhada mais detalhada na relação entre as variáveis de nosso dataframe.

Vejamos como se dá o lucro de cada filme em relação a sua classificação ("imdb_score")
 
Para esto vamos usar as funções básicas de plot() e abline(), onde plotaremos a dispersão de uma variável junto com a linha de regressão que melhor se ajusta aos dados.
 
O diagrama e o modelo de regressão serão criados com a fórmula _profit ~ rating_, adicionaremos um título em cada eixo  

---

```{r corr16}
# diagrama de dispersão de classificação e lucro
plot(movies$profit ~ movies$imdb_score,
     xlab = "Classificação",
     ylab = "Lucros (milhões U$S)",
     ylim = c(min(movies$profit, na.rm = T),max(movies$profit, na.rm = T)))

# linha de regressão adicionada diretamente no gráfico
abline(lm(movies$profit ~ movies$imdb_score), col="red", lwd = 2)
```

A linha de regressão do gráfico tem os seguintes parâmetros

```{r}
reg_movies1 <- lm(movies$profit ~ movies$imdb_score)
broom::tidy(reg_movies1, conf.int = T)
```

---

Olhando o gráfico é difícil perceber se a linha de regressão apresenta alguma tendência positiva ou negativa. Isso é causado pelos altos valores negativos de alguns filmes. Veamos qual é o campeão de desperdiço monetário e logo depois vamos eliminar todos os filmes com maiores lucros negativos, a fim de limpar o gráfico.

And the winner is!!!....

```{r corr17}
# seleção do filme menos lucrativo do conjunto 
rubbish <- which(movies$profit < -10000)
# mostrando alguns dados
movies[rubbish, c(2, 4, 10, 12, 21, 24, 29)]
```

Eliminação de filmes menos lucrativos...

```{r corr18}
movies2 <- filter(movies, movies$profit > -100)
# diagrama de dispersão de classificação e lucro
plot(movies2$profit ~ movies2$imdb_score,
     xlab = "Classificação",
     ylab = "Lucros",
     ylim = c(min(movies2$profit, na.rm = T),max(movies2$profit, na.rm = T)))

# linha de regressão adicionada diretamente no gráfico
abline(lm(movies2$profit ~ movies2$imdb_score), col="red", lwd = 2)

```

---

```{r}
# cálculo de regressão linear sem valor discrepante
reg_movies2 <- lm(movies2$profit ~ movies2$imdb_score)
broom::tidy(reg_movies2, conf.int = T)
```

Note-se como na primeira regressão os valores de _p_ indicavam que os resultados não eram confiáveis ao 95% de confiança e compare com os valores obtidos nesta segunda regressão sem o valor discrepante retirado.

A retirada de valor(es) discrepante(s), quando corresponda (confira o tratamento de outliers no tutorial 01), pode ser feita diretamente no cálculo da regressão linear:

```{r}
reg_movies3 <- lm(profit ~ imdb_score, data = movies %>% 
  filter(profit > -100))
broom::tidy(reg_movies3, conf.int = T)
```

---

O gráfico acima aparenta mostrar que quanto mais alta a sua classificação, mais alto o lucro.

Uma outra forma de expressar a frase anterior, seria dizer que existe uma correlação positiva (ainda que não expressiva) entre a classificação do filme e o seu lucro nos dados apresentados.

Certo que também visualizamos filmes com alta classificação e baixo lucro e ao contrário.

**Lembre o expressado no começo: correlação não supõe causa!**
  
A correlação pode ser vista como um indicativo que deve ser estudado com mais profundidade.

---

#### Calculando a  Correlação com _R_

Que tipos de relações existem entre as variáveis de nosso dataframe e como podemos avaliar elas em forma quantitativa?

O primeiro é calcular as correlações usando a função _cor()_.

A função _cor()_ pode ser usada também para calcular uma matriz de correlação e em sua forma mais simples é:


**cor(x, method = "Pearson", use = "complete.obs")**, sendo **x** uma matriz numérica ou dataframe, o método padrão é correlação de "Pearson" e no caso de existir NAs ou dados faltantes, o argumento "complete.obs" elimina do cálculo as linhas correspondientes.

Além do método "Pearson" para variáveis numéricas, existem os métodos "Spearman" e "Kendall" para análise de variáveis quantitativas.

---

```{r corr19}  
# Calcular a correlação de Pearson entre classificação e lucro
cor(movies2$imdb_score, movies2$profit)

# calcular a matriz de correlação entre variáveis de nosso dataframe, excluindo algumas colunas (veja str())
cor(movies2[, c(9, 13, 23, 26, 29)])
```

---

Note que pode ser especificado que tipo de coeficiente de correlação desseja-se calcular. Aqui tem de se ter um cuidado especial, devido que algumas supossições devem ser assumidas para cada método, por exemplo: os métodos de Kendall e Spearmas fazem sentido apenas se os seus dados estão ordenados, ou seja primeiro tem de ordenar os dados prévio ao cálculo.

Por outro lado, o método padrão de **Correlação de Pearson**, assume que _existe uma correlação linear entre suas variáveis e elas estão normalmente distribuídas._
 
No cálculo de correlações também pode ser usada a função _Hmisc::rcorr_, para calcular os níveis de significancia para as correlações de Pearson e Spearman.
 
Veja que a matriz de correlação é realmente uma tabela que apresenta os coeficientes de correlação entre as variáveis, e isso nos dá uma rápida noção das relações aproximadas entre elas.

---
 
#### Explorando visualmente as correlações: Matriz de correlações

Vamos fazer um gráfico com a matriz de correlações, usando as variáveis disponíveis no dataframe. Esta plotagem nos permite visualizar rápidamente quail variável tem correlação positiva, negativa, fraca ou forte com outras variáveis.

 Para conseguir esse gráfico vamos usar a função _GGally::ggcorr_.
 
 A função é chamada simplesmente incluindo o dataframe com as variáveis a calcular a correlação, a saída é uma matriz triangular, com código de cores e os nomes das variáveis. As variáveis não numérica são ignoradas no cálculo.
 

---

```{r corr20}
library(GGally)
ggcorr(movies2[, c(4, 9, 13, 19, 23, 24, 26, 28, 29)])
```

---

Assim nesta matriz de correlação criada, pode-se ler por exemplo a variável "profit" que tem uma forte correlação positiva com "gross", acorde a seu color vermelho e ao contrário, "rating" tem uma fraca correlação negativa com "year".

Os coeficientes de correlação estão sempre entre -1 e 1, inclusive.

Uma correlação de -1, implica uma perfecta correlação negativa, ou seja enquanto os valores de X aumentam, os de Y diminuem e ao contrário, uma correlação de +1, implica que ambas variáveis crescem simultáneamente nos eixos do gráfico.

Na maioria dos casos, o coeficiente estará entre esses valores de -1 e 1.

Se além das cores, deseja-se incluir o valor numérico da correlação, pode se incluir na função **label = TRUE** e se desejar que a transparência do valor acompanhe a transparência da cor, adicione **label_alpha =TRUE**.
 

---

```{r corr21} 
# valores e transpârencia adicionadas
ggcorr(movies[, c(4, 9, 13, 19, 23, 24, 26, 28, 29)], 
               label = TRUE, 
               label_alpha = TRUE)
```

---

Nos gráficos a seguir, veremos uma forte correlação, onde a inclinação da linha de regressão (x/y) é proxima de 1 ou -1, enquanto uma correlação fraca produz uma linha de regressão com quase nenhuma inclinação. Uma inclinação de -1 ou 1 indica que as variáveis tem uma relação estreita.

No caso do dataframe dos filmes, as linhas de regressão podem indicar interdependencia entre elas. 

Por exemplo, vimos no gráfico anterior que profit e rating tem uma linha de regressão moderada de inclinação positiva e vendo a correlação calculada, vemos que seu valor é 0.3.
 
 
---

#### Tipos de Correlação

Vejamos diferentes tipos de gráficos para diferentes tipos de correlações.

Correlação forte: votes vs. reviews

Olhando o valor da correlação podemos ver que tem um valor de 0.8, o que implica uma inclinação da linha de regressão perto de 1.

Este gráfico será feito com o pacote ggplot2.
Deste pacote, vamos usar a função qplot, que produz diversos tipos de gráficos, dependendo do tipo de geometria passada.

No código, a geometria foi definida de duas formas: como _point_ para mostrar o gráfico de dispersão das variáveis e como _smooth_ para sobrepor a linha de regressão ou tendência.

O método foi definido como _lm_, o que implica que a linha de tendência será a nossa conhecida linha de regressão linear.

---

```{r corr22} 
# Plot votes vs reviews
library(ggplot2)

qplot(num_voted_users, num_user_for_reviews, data = movies2, 
      geom   = c("point", "smooth"), 
      alpha  = I(1 / 5), 
      method = "lm", 
      se = FALSE)
```

---

O argumento "alpha" referente a opacidade, implica usar uma escala de transparência nos pontos incluídos no diagrama de dispersão, semelhante ao usado em _ggcorr_ anteriormente para as etiquetas.

Nesta configuração, necessita-se a sobreposição de ao mínimo 5 pontos para atingir a opacidade total. Incrementando ou diminuindo o número do denominador no argumento alpha, modificará o número de pontos requerido para atingir a opacidade.

Desta forma é possível visualizar com facilidade onde existe concentração de pontos no gráfico, o que pode conduzir a novas pesquisas nos dados.

Experimente no fragmento anterior modificar o argumento "alpha" com diversos valores no denominador.

---

#### Correlação fraca: gráfico de "profit" vs "year

Vejamos como se vê uma correlação negativa e "fraca", no seguinte gráfico.

Desta vez no vamos impor nenhum método para a linha de tendência, pelo que ela deve variar acorde a data em forma curvilinear, que é o método padrão para a função.

Notará também que existe uma pequena área cinza entorno da curva, é o intervalo de confiança da linha, o que será explicado posteriormente.

---

```{r corr23} 
# Plot profit over years
qplot(title_year, profit, data = movies2, 
      geom = c("point", "smooth"), 
      alpha = I(1 / 5))
```

---

Agora que estamos olhando a linha de tendência e o intervalo de confiança, podemos fazer as seguintes observações:

1- A parte inicial da curva apresenta um incremento do lucro por ano;

2- A área do intervalo de confiança inicialmente é maior enquanto o número de pontos é pouco;

3- A medida que a curva entra em áreas com um crescente número de pontos, ela diminue de tamanho até práticamente se confundir com a própria curva, que aparenta um declínio nos últimos anos.

Concluindo, o gráfico do intervalo de confiança em conjunto com a linha de tendência, nos mostra que temos um grau de incerteza com nossa linha de regressão e ele é maior na medida que temos poucas observações enquanto nossa confiança aumenta quando temos maior quantidade de observações. 

Isto revela-se muito útil já que podemos visualizar como as relações entre variáveis se comportam através de nosso dataframe e nos indica onde se concentram nossas observações.

O problema pode acontecer quando fica dificil determinar quando a relação é positiva ou negativa.
 
Vamos graficar as mesmas variáveis, mas desta vez especificando a regressão linear, sem intervalo de confiança.

---

```{r corr24} 
# Plot the years on the x-axis, profit on the y-axis
qplot(title_year, profit, data = movies2, 
      geom   = c("point", "smooth"), 
      method = "lm",                # regressão linear simples
      alpha  = I(1 / 5),            # transparência
      se     = FALSE)              # sem intervalo de confiança
```

---

Agora a linha de tendência que indica a correlação ficou mais clara e se olhamos o gráfico de matriz de correlações, vemos que o valor da correlação é -0.1.

---
 
#### Juntando cacos...

Vamos ver agora uma outra função muito útil de _GGally::ggpairs_.

Ela permite criar uma matriz que apresenta não apenas os coeficientes de correlação de multiplas variáveis mas também o diagrama de dispersão e a curva de densidade,  junto com linha de ajuste e o intervalo de confiança.

Assim conseguimos cobrir todos os tópicos deste tutorial num simples gráfico. 

No seguinte fragmento de código escolhimos quatro variáveis (pode escolher as que desejar) e criamos o gráfico final mencionado. 

---
 

```{r corr25} 
# Plug in your three favorite variables and tinker away!
GGally::ggpairs(movies2, 
        columns = c("budget", "num_voted_users", "profit", "imdb_score"), 
        upper   = list(continuous = wrap("cor", size = 8, alpha = 1)), 
        lower   = list(continuous = wrap("smooth", alpha = 0.5)))
```

---

Como já deve ter pensado, existem inúmeros cenários para os quais um determinado gráfico é o ideal, a chave é entender que técnica de visualização é a mais adequada e como usá-la para lograr os melhores resultados.

#### Matriz de correlação com níveis de significância ( _p-values_ ) 

A função _Hmisc::rcorr_ permite calcular níveis de significância para as correlações de "Pearson" e "Spearman", para todas as colunas possíveis dos dados.

Na forma simples, é:

_rcorr(x, type = c("Pearson", "Spearman"))_

Usando agora os dados 'datasets::mtcars' (explore o significado de cada coluna com ?mtcars), vejamos primeiro as correlações:


```{r corr26}
library(Hmisc)
mtcars <- mtcars[,1:7]
cor.mt <- round(cor(mtcars),2)
cor.mt
```

---

Com o uso de _rcorr_ podemos calcular além das correlações o nível de significância:

```{r corr27}
cor.mt2 <- rcorr(as.matrix(mtcars))
cor.mt2
```

---

Na primeira matriz temos as correlações enquanto na segunda são apresentados os níveis de significância da correlação calculada.

Para extrair individualmente as tabelas, podemos usar:

**cor.mt2$r** 

ou 

**cor.mt2$P**

A seguinte função permite visualizar uma tabela de 4 colunas com a seguinte informação:

1- nome das linhas ou variáveis 1 para a correlação

2- nome das colunas ou variáveis 2 para correlação

3- coeficientes de correlação

4- valores de p para a correlação

```{r corr28}
## Função para criar tabela de correlação e valores p de significância
## sendo corval, os valores de coeficientes de correlação
## e pval, os valores de significãncia da correlação calculada
tabCorr <- function(corval,pval){
  sup <- upper.tri(corval)
  data.frame(
    row    = row.names(corval)[row(corval)[sup]],
    column = row.names(corval)[col(corval)[sup]],
    cor    = (corval)[sup],
    p      = pval[sup]
  )
}
```

---

uso da função:

```{r corr29}
cor.mt2 <- rcorr(as.matrix(mtcars[,1:7]))

t <- (tabCorr(cor.mt2$r, cor.mt2$P))
t
```

---

Para a visualização, vamos escolher a função **PerformanceAnalytics::chart.Correlation**. 


```{r, corr30, message=FALSE, warning=FALSE}
library(PerformanceAnalytics)
dados <- mtcars[, c(1,3,4,5,6,7)]
chart.Correlation(dados, histogram = T, pch = 19)
```


```{r}
sessionInfo()
```

