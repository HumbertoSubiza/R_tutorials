---
title: "Regressão Linear"
author: "Walter Humberto Subiza Pina"
date: "1 de março 2019"
output: html_document

---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



## Regressão Linear

A regressão linear é usada quando queremos predecir o valor de uma variável _Y_, chamada de resposta, baseado em uma ou mais variáveis preditores ou explicativas, denominadas _Xs_.

O objetivo é estabelecer uma relação matematica linear através de uma fórmula, que relacione a(s) variáveis explicativas e a variável resposta, de forma que, quando os valores das variáveis explicativas são conhecidas, é possível estimar o valor da variável resposta.

---

#### Introdução

O objetivo exposto acima, pode ser generalizado através da seguinte equação:

$$Y= β_1 + β_2 X + ϵ$$

onde, $β_1$ é o intercepto, ou ponto de cruzamento da reta de regressão com o eixo _Y_ e $β_2$ é o coeficiente angular da inclinação da reta em relação ao eixo _X_. 

Os dois coeficientes juntos são chamados de **coeficientes de regressâo**. Finalmente, _ϵ_ é o termo de erro que o modelo é incapaz de explicar.

---



####Análise gráfico

Antes de começar o cálculo da regressão, é de boa prática analisar e entender o comportamento das nossas variáveis. O análise gráfico e um estudo de correlação vai ajudar nesse processo.

O exercício consiste em construir um modelo simples de regressão, que possa ser usado para calcular uma distância a percorrer, a partir da relação linear da distância com a velocidade (variáveis "dist" e "speed", respectivamente, ambas conhecidas). 

Normalmente usam-se três ferramentas para entender e visualisar o comportamento das variáveis, que são:

1- **Gráfico de dispersão**, permite visualizar a relação entre as variáveis explicativas e resposta

2- **Gráfico das 5 medidas ou Box-plot**, permite identificar valores discrepantes en uma variável. Valores discrepantes ou extremos podem afetar significativamente a magnitude  ou direção da linha de melhor ajuste.

3- **Gráfico de densidade**, para analisar a variável explicativa, idealmente deveria ter uma distribuição perto da normal, sem desvios a direita ou esquerda (assimetrias ou _skew_).

Vejamos cada uma delas:

---

#####Gráfico de dispersão

Ajudam a visualizar a relação entre a variável explicativa e a resposta. Se tiver mais de uma variável explicativa, deve ser feito um gráfico para cada uma em forma independente, incluíndo a linha de melhor ajuste.

```{r}
scatter.smooth(cars$speed, cars$dist,
               main="Relação Velocidade-Distância \n e linha de melhor ajuste",
               xlab = "Velocidade",
               ylab = "Distância")
```

---

O gráfico sugere que existe uma relação linear crescente entre a velocidade e distância. Isto é um bom sinal já que um dos supostos em regressão linear é que existe uma relação linear e aditiva entre as variáveis explicativas e a resposta.

---

#####Gráfico dos 5 números ou _box-plot_

Qualquer observação que exceda  uma vez e meia a amplitude inter-quartílica, ou seja ($1,5 * (Q3-Q1)$), é considerado um valor discrepante ou extremo (outlier). $Q3$ e $Q1$ são os 75 e 25 valores de percentís da variável considerada.

```{r}
par(mfrow=c(1, 2))  # dividir o espaço em duas colunas

boxplot(cars$speed, 
        main="Velocidade", 
        sub=paste("Valores extremos: ", 
                  boxplot.stats(cars$speed)$out))

boxplot(cars$dist, 
        main="Distância", 
        sub=paste("Valores extremos: ", 
                  boxplot.stats(cars$dist)$out)) 
```

Como se aprecia, apenas o valor de 120 na variável "dist" aparenta ser um valor extremo, no caso da variável "speed" não apresenta nenhum valor fora do AIQ.

---

#####Gráfico de densidade

O gráfico ajuda a verificar a normalidade da distribuição de cada variável.

```{r}
library(e1071)
par(mfrow=c(1, 2))  # divide a área para dois gráficos separados
# primeiro grafico com Velocidade
plot(density(cars$speed), 
     main="Gráfico de densidad \n para Velocidade", 
     ylab="Densidade", 
     sub=paste("Assimetria:", 
               round(e1071::skewness(cars$speed), 2)))  # density plot for 'speed'
polygon(density(cars$speed), col="red")

plot(density(cars$dist), 
     main="Gráfico de densidad \n para Distância", 
     ylab="Densidade", 
     sub=paste("Assimetria:", 
               round(e1071::skewness(cars$dist), 2)))  # density plot for 'dist'
polygon(density(cars$dist), col="red")


```

---

No caso da velocidade, nota-se que a curva de densidade é muito próxima da normal, enquando a de distância apresenta uma leve assimetria à direita. A presença do outlier de 120 é visível.

---


#### Construindo um modelo linear

Uma vez analisada gráficamente e numéricamente a relação entre as variáveis, vamos ver ver como se calcula o modelo linear de regressão. 
A função usada é **lm()** que tem dois argumentos de entrada, o primeiro sendo a fórmula de cálculo e o segundo os dados. 
Os dados são normalmente um dataframe e a fórmula é um objeto de classe fórmula do **R** , ainda que seja comum escrever a fórmula diretamente como no exemplo a seguir:



```{r}
modelo_linear <- lm(dist ~ speed, data=cars)  # argumentos: fórmula, dados
print(modelo_linear)
```


O modelo linear calculado, estabelece a relação entre o preditor e a reposta, na forma de uma fórmula matemática. Os coeficientes, como vemos acima, tem o intercepto: -17.579,  e o coeficiente da velocidade: +3.932

Em outras palavras:

$distância = Intercepto + (β ∗ velocidade)$ ===> $distância = −17.579 + 3.932 ∗ velocidade$

---

#### Análise da Regressão Linear

Agora que temos um modelo para calcular os valores da distância, sabendo a velocidade, será que podemos usar o modelo?
A resposta é **não!**. 

Antes de liberar o seu uso devemos garantir que es estatísticamente significativo, para isso vamos ver algumas estatistísticas de qualidade.


```{r}
summary(modelo_linear)
```


---


##### O valor p: verificando a significancia estatística do modelo.

O resumo acima tem várias informações de importância. A primeira é o valor _p_ do modelo (na última linha) e o valor _p_ de cada coeficiente calculado (coluna à direita embaixo de ‘Coefficients’).

Os valores de _p_ são muito importantes, já que podemos considerar um modelo linear como estatísticamente significativo se ele é inferior a determinado valor previamente escolhido como "nivel de significancia estatística" (o nível mais usado é 0.05).
Visualmente também podemos verificar a significancia pelas estrelas no final da linha, quanto mais estrelas, mais significativo é o coeficiente calculado.

**Hipótese Nula e alternativa**

Quando adotamos um valor de _p_ para nossa hipótese _Nula_ ou $H_0$, sempre temos uma hipótese _alternativa_ $H_1$ (ou $H_a$) associada. 

No caso da regresssão linear, a hipótese Nula $H_0$ é que os coeficientes das variáveis são iguais a zero (as variáveis são independentes) e a hipótese Alternativa $H_1$, é que os coeficientes não são iguais a zero, então deveria uma relação entre a(s) variável(is) explicativas e a variável resposta.

No nosso modelo podemos verificar que tanto o modelo como os coeficientes apresentam valores de _p_ inferiores a 0.05, pelo que o modelo e os coeficientes calculados são significativos e além disso, podemos rejeitar a hipótese _Nula_ de que não existe relação entre as variáveis explicativas e resposta, com um nível de confiança de 0.95%.



##### Valor t

Podemos interpretar o valor de _t_ da seguinte forma: valores maiores de _t_ indicam que é menos provável que os coeficientes não sejam zero por pura aleatoridade (e por conseguinte estivermos errado com nosso modelo). Assim sendo quando maior o valor de _t_, melhor.

---


##### Valor Pr(>|t|)

É a probabilidade de ter um valor de _t_ tão alto ou mais que o que foi calculado quando a hipótese _Nula_ é verdadeira (o coeficiente β é zero o não existe relação). Por conseguinte, se o valor de Pr(>|t|) é baixo, os coeficientes são significativos (lembre que é _probabilidade_!), se o valor é alto, os coeficientes não seriam significativos.

Qual a interpretação de toda essa informação? Quando o valor _p_ é inferior ao nível de significancia desejado (< 0.05),
podemos com alguma certeza, rejeitar a hipótese _Nula_ que o coeficiente de β é zero. 

No nosso caso, para o modelo "linearMod", ambos os valores de _p_ estão muito abaixo de 0.05, e podemos concluir que nosso modelo é estatísticamente significativo, ou seja reflete a real dependência entre as variáveis.

É de muita importância que o modelo seja estatísticamente significativo antes de continuar e usá-lo para calcular ou estimar valores da variável resposta.


Como calculamos os valores de _p_ e _t_?

Quando tanto os coeficientes do modelo como seus desvio padrão são conhecidos, a fórmula de cálculo é:


_t estatistico_ =  (coeficiente β) / Devio Padrão

Vejamos passo a passo:

---


```{r}
resumo_modelo <- summary(modelo_linear)  # captura o resumo do modelo como objeto

modelo_coef <- resumo_modelo$coefficients  # coeficientes do modelo

beta.estimado <- modelo_coef["speed", "Estimate"]  #estimado de "beta" para velocidade

desv.pad <- modelo_coef["speed", "Std. Error"]  # desvio padrão da velocidade

t_valor <- beta.estimado/desv.pad  # calculo do t estatistico

# calculo do valor de p, ver stats:TDist, pt é a distribuição da função t, com df graus de liberdade
p_valor <- 2*pt(-abs(t_valor), df=nrow(cars)-ncol(cars))  

f_estatistico <- resumo_modelo$fstatistic  # f estatistico

f <- summary(modelo_linear)$fstatistic  # parametros para o modelo com  p calculado

# calculo do valor de p do modelo, ver stats:FDist
modelo_p <- pf(f[1], f[2], f[3], lower=FALSE)

t_valor
p_valor
f_estatistico
modelo_p 
```


---

#####$R^2$ e $\bar R^2$

O valor de R quadrado, é calculado por:

$$ \ R^2 = 1- \frac{SQR}{SQT} $$

Onde _SQR_ é a soma dos quadrados dos resíduos dados por $SQR = \sum_i^n ( y_i - \hat  y)^2$ e _SQT_ é a soma dos quadrados total, dados por $SQT = \sum_i^n (y_i- \bar y)_2$.

Aqui, $\hat y_i$ é o valor ajustado para a observação _i_ e $\bar y$ é o valor médio de _Y_.

---

Sabemos também que a soma dos erros quadrados explicada (_SQE_), indica a diferência entre a média das observações e o valor estimado para cada observação:$SQE = \sum_i^n (\hat y_i -  \bar y_i)^2$. 

Assim $SQT = SQE + SQR$.

---

Não necessariamente devemos descartar um modelo que apresenta valores baixos de $R^2$. Merece prestar atenção ao valor de _AIC_ e a precisão dos valores calculados na amostra para decidir acerca da acurácia do modelo.

Em referência ao $\bar R^2$: na medida que são adicionadas mais variáveis explicativas ao modelo o valor de $R^2$ deverá ser maior que aquele de um modelo menor. 

Isto deve-se a que como todas as variáveis do modelo original estão presentes, sua contribuição a explicar a variável resposta estará presente também no modelo acrescido, assim sendo quaisquer novas variáveis adicionadas, apenas soman na variação já explicada.

Aqui é onde o $\bar R^2$ vem a nos ajudar. O valor de $\bar R^2$ penaliza aqueles termos explicativos que não trazem muita contribuição nos modelos. Assim quando comparamos modelos aninhados, é uma boa práctica olhar o valor do $R^2$ em relação ao $\bar R^2$.

A fórmula do $\bar R^2$ é:

---


 $$ \ \bar R^2 = 1-  \frac{EQM} {EQT}$$

---


Onde $\ EQM=  \frac{SQR} {(n-q)}$ e $\ SQT= \frac{STQ} {(n-1)}$, sendo _n_ o número de observações e _q_ o número de coeficientes no modelo, dado pelo número de variáveis explicativas mais uma constante ($k+1$).

Por conseguinte, com as adequadas transformações, de numerador e denominador, a relação entre $R^2$ e$\bar R^2$ é:

$$ \bar R^2 = 1-  \frac{(1−R^2) (n−1)} {n−q}$$

---

#####Erro padrão e F-estatístico

Ambas estatísticas são medidas da qualidade de um ajuste.


$$ Erro Padrão = \sqrt{EQM} = \sqrt{\frac{SQR}{n-q}}$$


$$F-estatistico = \frac{QMR}{EQM}$$

Onde _QMR_ é o quadrado médio da regressão, calculado por:


$$ QMR = \frac {\sum_i^n (\hat {y_i} − \bar{y})} {q−1}  = \frac{SQE}{q−1}$$


Sendo $SQE$, a soma dos erros quadrados explicada, como já visto.

---

#####AIC e BIC

O critério de informação de Akaike (AIC), (Akaike, 1974) e o critério de informação Bayesiano (BIC), (Schwarz, 1978), são também medidas da qualidade do ajustamento de um modelo estatístico estimado e podem ser de utilidade no momento de selecionar o melhor modelo dentre vários.

Ambos dependen do valor maximizado da função de verosemelhança _L_ para o modelo estimado.


O AIC é definido por:


$$AIC= (-2) * ln(L) + (2*k)$$

onde _k_ é o número de parâmetros do modelo e BIC é definido por:

$$BIC = (−2) * ln(L) + k*ln(n)$$

sendo _n_ o número de observações.

Quando comparamos diversos modelos, àqueles com menores valores de AIC e BIC devem ser selecionados.

```{r}
AIC(modelo_linear)  # AIC => 419.1569
BIC(modelo_linear)  # BIC => 424.8929
```

---

Como sabemos se o modelo escolhido é o que melhor se adequa para nossos dados?

As medidas mais usadas na seleção de modelos são:



| ESTATISTICA                        | CRITERIO DE SELEÇÃO, MELHOR QUANDO:|
|-------------------------------------|---------------------------|
| $R^2$                                       | Maior valor (> 0.70)|
| $R^2$ _ajustado_                                  |Maior valor|
| F-estatistico                                    |Maior valor|
| Erro Padrão                                     |Perto de zero|
| Estatística _t_ |Deve ser maior a 1.96 para  p < 0.05 |
| AIC                                              |Menor valor|
| BIC                                             |Menor valor|
| MAPE (percentagem erro medio absoluto)           |Menor valor|
| MSE (Erro médio quadrático)                        |Menor valor|
| Acurácia mín-máx => mean(min(real, calculado)/max(real, calculado)) |Maior valor|

---

Até aqui calculamos um modelo de regressão usando todos los dados disponíveis. Assim sendo, não sabemos que pode acontecer se novos dados são adicionados ao modelo.

A prática mais usual para testar nosso modelo com conjunto de dados diferentes é dividir eles em dois conjuntos, uno chamaremos de treino e outro de teste. Por exemplo podemos dividir um 75% dos dados para treino e 25 para teste. A escolha é totalmente arbitrária.

Assim, vamos ter um modelo de cálculo para um 25% dos dados (ou àquela quantidade que escolheu) e através de diversas medidas de acurácia, como as já vistas (min-max, MAPE...) podemos ter uma medida da acurácia do modelo calculado.

Vamos ver como fazemos isto....

---

Passo 1 - Crear um conjunto de treino e teste a partir dos dados obtidos

```{r}
set.seed(123456)
Indice_col <- sample(1:nrow(cars), 0.75*nrow(cars))
treino_dados <- cars[Indice_col,]
teste_dados <- cars[-Indice_col,]
```

---

Passo 2 - Calcular o modelo com os dados de treino

```{r}
modelo <- lm(dist~speed, data=treino_dados)
dist_calculada <- predict(modelo, teste_dados)

```

---

Passo 3 -  Ver as estatísticas do modelo

```{r}
summary(modelo)
AIC(modelo)
```

---

Do resumo do modelo, vemos que tanto o valor _p_ do modelo, como os coeficientes calculados tem valores inferiores ao nível de significancia (0.05), pelo que são estatísticamente significativos. Compare o $R^2$ e o $R^2$ ajustado com o modelo completo original.

---

Passo 4-  Calcular a acurácia dos valores calculados e os erros

Uma simples correlação entre os valores reais e calculados pode ser usado para ter uma medida da acurácia do modelo. Uma alta correlação significa que os valores reais e os calculados tem direção semelhante de crescimento ou decrescimento.

```{r}
real_cal <- data.frame(cbind(reais=teste_dados$dist, cal=dist_calculada))
(corr_acur <- cor(real_cal)[2])
```

---

Cálculo do _máx-mín_ e _MAPE_


```{r}
(max_min <- mean(apply(real_cal, 1, min)/apply(real_cal,1,max)))
(mape <- mean(abs((real_cal$cal-real_cal$reais))/real_cal$reais))
```


---


#####Validação cruzada K-folhas (K-fold cross validation)

Vamos supor que o modelo fornece uma boa predição ou cálculo com uma separação dos dados de 20% (dados de teste), será que a acurácia do modelo seria mantida se tivessem sido escolhidos outros dados de treino e teste? É importante verificar o modelo ao máximo e uma maneira de fazer isso, é usar diferentes subconjuntos de dados de treinamento e teste.

A metodologia é separar os dados em k-partes mutuamente exclusivas de amostras treino-teste. Isto é feito para cada "k" amostra aleatória e finalmente promediamos os "k" erros medios quadráticos. Podemos usar essa metodologia para comparar diferentes modelos lineares.

Dessa forma precisamos verificar dois coisas:

1- Se a acurácia do modelo não varia muito de amostra em amostra, e

2- Se as linhas de regressão no variam muito em inclinação ou valor.

Em outras palavras, as linhas de regressão devem ser o mais paralelas e próximas possíveis. 

Vamos usar a biblioteca _DAAG_ (Data Analysis and Graphic Data and Functions), se não a tiver, faça primeiro a instalação (install.packages("DAAG")). 

O pacote DAAG tem a função _CVlm_ (Cross Validation for Linear Regression), que permite fazer o cálculo, selecionando o número de amostras aleatórias em que serão dividos os dados (parâmetro _m_). Veja ?DAAG.

Nesta avaliação os dados serão divididos em 5 grupos diferentes de treino-teste. 

---

```{r warning=FALSE, message=FALSE}
library(DAAG)
par(mfrow=c(1, 1)) 
cv_resultados <- CVlm(data=cars, form.lm = dist ~ speed, m=5, dots = F, seed=29, legend.pos = "topleft", printit = T, main="Simbolos pequenos são valores \n calculados e grandes os reais")

```

---

Até aqui analisamos os conceitos básicos de regressão linear. Precisamos entender que a regressão linear é baseado em alguns presupostos e devemos ter cuidado especial quando temos diferentes variáveis explicativas.

---

FIM de Regressão linear

---

```{r}
sessionInfo()
save(list = ls(), file = "regressão_linear_all.Rdata")
```





